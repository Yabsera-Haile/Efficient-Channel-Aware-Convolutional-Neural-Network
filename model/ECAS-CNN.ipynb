{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:21.535361Z",
     "iopub.status.busy": "2025-03-15T17:53:21.535024Z",
     "iopub.status.idle": "2025-03-15T17:53:29.845952Z",
     "shell.execute_reply": "2025-03-15T17:53:29.844994Z",
     "shell.execute_reply.started": "2025-03-15T17:53:21.535333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:29.847420Z",
     "iopub.status.busy": "2025-03-15T17:53:29.847030Z",
     "iopub.status.idle": "2025-03-15T17:53:29.851860Z",
     "shell.execute_reply": "2025-03-15T17:53:29.850859Z",
     "shell.execute_reply.started": "2025-03-15T17:53:29.847398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": '/kaggle/input/mel-spectrogram-for-gtzn-dataset/melspectrograms',\n",
    "    \"arch\": 'ECASCNN',\n",
    "    \"workers\": 4,\n",
    "    \"epochs\": 100,\n",
    "    \"start_epoch\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"resume\": False,\n",
    "    \"evaluate\": False,\n",
    "    \"checkpoint_dir\": \"/kaggle/working/checkpoints/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eca_layer(nn.Module):\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBR(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(CBR, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECAS_CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ECAS_CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            CBR(in_channels=1, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            eca_layer(channel=128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=(0, 1))\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            CBR(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            eca_layer(channel=128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            CBR(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            eca_layer(channel=256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=(2 - 1) // 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  \n",
    "            nn.Linear(4096, 128), \n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1)\n",
    "        out3 = self.layer3(out2)\n",
    "        output = self.fc_layers(out3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:29.854162Z",
     "iopub.status.busy": "2025-03-15T17:53:29.853777Z",
     "iopub.status.idle": "2025-03-15T17:53:29.967747Z",
     "shell.execute_reply": "2025-03-15T17:53:29.966924Z",
     "shell.execute_reply.started": "2025-03-15T17:53:29.854125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:29.990674Z",
     "iopub.status.busy": "2025-03-15T17:53:29.990331Z",
     "iopub.status.idle": "2025-03-15T17:53:30.352926Z",
     "shell.execute_reply": "2025-03-15T17:53:30.352207Z",
     "shell.execute_reply.started": "2025-03-15T17:53:29.990645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ECAS_CNN(10).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:30.353907Z",
     "iopub.status.busy": "2025-03-15T17:53:30.353695Z",
     "iopub.status.idle": "2025-03-15T17:53:30.359327Z",
     "shell.execute_reply": "2025-03-15T17:53:30.358491Z",
     "shell.execute_reply.started": "2025-03-15T17:53:30.353888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:30.360493Z",
     "iopub.status.busy": "2025-03-15T17:53:30.360184Z",
     "iopub.status.idle": "2025-03-15T17:53:30.376697Z",
     "shell.execute_reply": "2025-03-15T17:53:30.375987Z",
     "shell.execute_reply.started": "2025-03-15T17:53:30.360465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=config['lr'], momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'], eta_min=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:30.379878Z",
     "iopub.status.busy": "2025-03-15T17:53:30.379662Z",
     "iopub.status.idle": "2025-03-15T17:53:30.387767Z",
     "shell.execute_reply": "2025-03-15T17:53:30.387013Z",
     "shell.execute_reply.started": "2025-03-15T17:53:30.379860Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(model, optimizer=None, scheduler=None):\n",
    "    path = os.path.join(config['checkpoint_dir'], 'last.pth')\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    else:\n",
    "        optimizer = None\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    else:\n",
    "        scheduler = None\n",
    "    epoch = checkpoint['epoch']\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    return model, optimizer, scheduler, epoch, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:30.389235Z",
     "iopub.status.busy": "2025-03-15T17:53:30.388988Z",
     "iopub.status.idle": "2025-03-15T17:53:30.405749Z",
     "shell.execute_reply": "2025-03-15T17:53:30.405018Z",
     "shell.execute_reply.started": "2025-03-15T17:53:30.389205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if config['resume']:\n",
    "        load_model(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:30.406826Z",
     "iopub.status.busy": "2025-03-15T17:53:30.406555Z",
     "iopub.status.idle": "2025-03-15T17:53:40.720326Z",
     "shell.execute_reply": "2025-03-15T17:53:40.719141Z",
     "shell.execute_reply.started": "2025-03-15T17:53:30.406799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(config['data'], 'train/')\n",
    "valdir = os.path.join(config['data'], 'validation/')\n",
    "testdir = os.path.join(config['data'], 'test/')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((130, 13)), \n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "       valdir,\n",
    "       transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  \n",
    "        transforms.Resize((130, 13)),\n",
    "        transforms.ToTensor(),\n",
    "      ])\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "       testdir,\n",
    "       transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  \n",
    "        transforms.Resize((130, 13)),\n",
    "        transforms.ToTensor(),\n",
    "      ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.722709Z",
     "iopub.status.busy": "2025-03-15T17:53:40.722406Z",
     "iopub.status.idle": "2025-03-15T17:53:40.728890Z",
     "shell.execute_reply": "2025-03-15T17:53:40.728066Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.722683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config['batch_size'], shuffle=True,\n",
    "        num_workers=config['workers'], pin_memory=True\n",
    " )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'], shuffle=False,\n",
    "    num_workers=config['workers'], pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'], shuffle=False,\n",
    "    num_workers=config['workers'], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.730113Z",
     "iopub.status.busy": "2025-03-15T17:53:40.729818Z",
     "iopub.status.idle": "2025-03-15T17:53:40.745767Z",
     "shell.execute_reply": "2025-03-15T17:53:40.744900Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.730081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.746893Z",
     "iopub.status.busy": "2025-03-15T17:53:40.746697Z",
     "iopub.status.idle": "2025-03-15T17:53:40.763905Z",
     "shell.execute_reply": "2025-03-15T17:53:40.763196Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.746874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        _, pred = output.max(1)\n",
    "        \n",
    "        correct = pred.eq(target).float().sum()\n",
    "       \n",
    "        acc = correct.mul(100.0 / batch_size)\n",
    "        \n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.764918Z",
     "iopub.status.busy": "2025-03-15T17:53:40.764712Z",
     "iopub.status.idle": "2025-03-15T17:53:40.779376Z",
     "shell.execute_reply": "2025-03-15T17:53:40.778695Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.764890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    accuracy_meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "           \n",
    "            \n",
    "            input = input.to(DEVICE, non_blocking=True)\n",
    "            target = target.to(DEVICE, non_blocking=True)\n",
    "\n",
    "    \n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        \n",
    "            acc = accuracy(output, target)\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            accuracy_meter.update(acc, input.size(0))\n",
    "\n",
    "\n",
    "    return losses.avg, accuracy_meter.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.780553Z",
     "iopub.status.busy": "2025-03-15T17:53:40.780258Z",
     "iopub.status.idle": "2025-03-15T17:53:40.795130Z",
     "shell.execute_reply": "2025-03-15T17:53:40.794423Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.780533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, best_acc, epoch):\n",
    "    path = os.path.join(config['checkpoint_dir'], 'last.pth')\n",
    "    torch.save(\n",
    "        {'model_state_dict'         : model.state_dict(),\n",
    "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
    "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
    "         'best_acc'                 : best_acc,\n",
    "         'epoch'                    : epoch},\n",
    "         path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.796160Z",
     "iopub.status.busy": "2025-03-15T17:53:40.795957Z",
     "iopub.status.idle": "2025-03-15T17:53:40.809990Z",
     "shell.execute_reply": "2025-03-15T17:53:40.809127Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.796133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accuracy_meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "      \n",
    "        input = input.to(DEVICE, non_blocking=True)\n",
    "        target = target.to(DEVICE, non_blocking=True)\n",
    "\n",
    "\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "    \n",
    "        acc = accuracy(output, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        accuracy_meter.update(acc, input.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "    return losses.avg, accuracy_meter.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.810906Z",
     "iopub.status.busy": "2025-03-15T17:53:40.810622Z",
     "iopub.status.idle": "2025-03-15T17:53:40.830269Z",
     "shell.execute_reply": "2025-03-15T17:53:40.829633Z",
     "shell.execute_reply.started": "2025-03-15T17:53:40.810888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = config['checkpoint_dir']\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T17:53:40.831202Z",
     "iopub.status.busy": "2025-03-15T17:53:40.830929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "\tTrain Acc 30.7933%\tTrain Loss 1.8728\t Learning Rate 0.1000000\n",
      "\tVal Acc 12.7127%\tVal Loss 2.5594\n",
      "Epoch 2\n",
      "\n",
      "\tTrain Acc 33.6587%\tTrain Loss 1.7768\t Learning Rate 0.0999766\n",
      "\tVal Acc 16.3163%\tVal Loss 2.9484\n",
      "Epoch 3\n",
      "\n",
      "\tTrain Acc 38.6136%\tTrain Loss 1.6455\t Learning Rate 0.0999063\n",
      "\tVal Acc 19.9199%\tVal Loss 2.4950\n",
      "Epoch 4\n",
      "\n",
      "\tTrain Acc 40.2528%\tTrain Loss 1.5793\t Learning Rate 0.0997892\n",
      "\tVal Acc 29.2292%\tVal Loss 1.7510\n",
      "Epoch 5\n",
      "\n",
      "\tTrain Acc 45.6707%\tTrain Loss 1.4771\t Learning Rate 0.0996254\n",
      "\tVal Acc 37.7377%\tVal Loss 1.5951\n",
      "Epoch 6\n",
      "\n",
      "\tTrain Acc 48.5360%\tTrain Loss 1.4037\t Learning Rate 0.0994152\n",
      "\tVal Acc 27.4274%\tVal Loss 2.0851\n",
      "Epoch 7\n",
      "\n",
      "\tTrain Acc 50.8759%\tTrain Loss 1.3646\t Learning Rate 0.0991586\n",
      "\tVal Acc 35.6356%\tVal Loss 2.0887\n",
      "Epoch 8\n",
      "\n",
      "\tTrain Acc 55.5681%\tTrain Loss 1.2445\t Learning Rate 0.0988560\n",
      "\tVal Acc 42.2422%\tVal Loss 1.8301\n",
      "Epoch 9\n",
      "\n",
      "\tTrain Acc 57.1822%\tTrain Loss 1.2034\t Learning Rate 0.0985077\n",
      "\tVal Acc 26.5265%\tVal Loss 2.0260\n",
      "Epoch 10\n",
      "\n",
      "\tTrain Acc 61.5741%\tTrain Loss 1.1182\t Learning Rate 0.0981140\n",
      "\tVal Acc 40.5405%\tVal Loss 1.7765\n",
      "Epoch 11\n",
      "\n",
      "\tTrain Acc 64.7773%\tTrain Loss 1.0287\t Learning Rate 0.0976752\n",
      "\tVal Acc 39.9399%\tVal Loss 2.5514\n",
      "Epoch 12\n",
      "\n",
      "\tTrain Acc 67.6051%\tTrain Loss 0.9552\t Learning Rate 0.0971918\n",
      "\tVal Acc 49.6497%\tVal Loss 1.9056\n",
      "Epoch 13\n",
      "\n",
      "\tTrain Acc 71.1461%\tTrain Loss 0.8625\t Learning Rate 0.0966644\n",
      "\tVal Acc 37.3373%\tVal Loss 3.7956\n",
      "Epoch 14\n",
      "\n",
      "\tTrain Acc 73.7487%\tTrain Loss 0.7809\t Learning Rate 0.0960933\n",
      "\tVal Acc 12.0120%\tVal Loss 7.6058\n"
     ]
    }
   ],
   "source": [
    "if config['evaluate']:\n",
    "        test_loss, test_acc = validate(test_loader, model, criterion)\n",
    "        print(\"\\tTest Acc {:.04f}%\\tTest Loss {:.04f}\".format(test_acc, test_loss))\n",
    "else:\n",
    "    best_acc = 0\n",
    "    for epoch in range(config['start_epoch'], config['epochs']):\n",
    "\n",
    "        curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch)\n",
    "        val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "      \n",
    "\n",
    "        is_best = val_acc > best_acc\n",
    "        best_acc = max(val_acc, best_acc)\n",
    "\n",
    "\n",
    "        if(is_best):\n",
    "            save_model(model, optimizer, scheduler, best_acc, epoch)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}\\n\")\n",
    "        print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc, train_loss, curr_lr))\n",
    "        print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc, val_loss))\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6824028,
     "sourceId": 10967771,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6834202,
     "sourceId": 10981553,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
