{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10981553,"sourceType":"datasetVersion","datasetId":6834202}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nimport wandb\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T17:19:51.083994Z","iopub.execute_input":"2025-03-16T17:19:51.084210Z","iopub.status.idle":"2025-03-16T17:19:51.098089Z","shell.execute_reply.started":"2025-03-16T17:19:51.084191Z","shell.execute_reply":"2025-03-16T17:19:51.097328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MelSpectrogramDataset(Dataset):\n    def __init__(self, root_dir):\n        self.root_dir = root_dir\n        self.classes = os.listdir(root_dir)\n        self.data = []\n        self.labels = []\n        \n        for idx, genre in enumerate(self.classes):\n            genre_path = os.path.join(root_dir, genre)\n            for file in os.listdir(genre_path):\n                self.data.append(os.path.join(genre_path, file))\n                self.labels.append(idx)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path = self.data[idx]\n        img = Image.open(img_path).convert('RGB') \n        img = np.array(img) \n        img = img.transpose((2, 0, 1))  \n        img = torch.from_numpy(img).float()  \n        label = self.labels[idx]\n        return img, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/input/mel-spectrogram-for-gtzn-dataset/melspectrograms/train'\nval_dir = '/kaggle/input/mel-spectrogram-for-gtzn-dataset/melspectrograms/validation'\ntest_dir = '/kaggle/input/mel-spectrogram-for-gtzn-dataset/melspectrograms/test'\n\ntrain_dataset = MelSpectrogramDataset(train_dir)\nval_dataset = MelSpectrogramDataset(val_dir)\ntest_dataset = MelSpectrogramDataset(test_dir)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 32, (3,3)),\n            nn.ReLU(),\n            nn.MaxPool2d((3,3), (2,2), padding=(1,1)),\n            nn.BatchNorm2d(32),\n            \n            nn.Conv2d(32, 32, (3,3)),\n            nn.ReLU(),\n            nn.MaxPool2d((3,3), (2,2), padding=(1,1)),\n            nn.BatchNorm2d(32),\n            \n            nn.Conv2d(32, 32, (2,2)),\n            nn.ReLU(),\n            nn.MaxPool2d((2,2), (2,2), padding=(0,1)),\n            nn.BatchNorm2d(32),\n            \n            nn.Flatten(),\n            nn.Linear(42624, 64), \n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 10)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nmodel = CNN()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\nscheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T15:44:16.835780Z","iopub.execute_input":"2025-03-16T15:44:16.836104Z","iopub.status.idle":"2025-03-16T15:44:18.832238Z","shell.execute_reply.started":"2025-03-16T15:44:16.836078Z","shell.execute_reply":"2025-03-16T15:44:18.831326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(30):\n    model.train()\n    running_loss = 0.0\n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/30')\n    for X_batch, y_batch in pbar:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        wandb.log({\"Train Loss\": loss.item()})\n    \n    print(f'Loss: {running_loss / len(train_loader)}')\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    y_pred = []\n    y_true = []\n    with torch.no_grad():\n        pbar_val = tqdm(val_loader, desc='Validation')\n        for X_batch, y_batch in pbar_val:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == y_batch).sum().item()\n            y_pred.extend(predicted.cpu().numpy())\n            y_true.extend(y_batch.cpu().numpy())\n        \n        accuracy = correct / len(val_dataset)\n        precision = precision_score(y_true, y_pred, average='macro')\n        recall = recall_score(y_true, y_pred, average='macro')\n        f1 = f1_score(y_true, y_pred, average='macro')\n\n\n        print(f'Validation Loss: {val_loss / len(val_loader)}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n    \n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-16T20:00:29.050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ntest_loss = 0.0\ncorrect = 0\nwith torch.no_grad():\n    pbar_test = tqdm(test_loader, desc='Test')\n    for X_batch, y_batch in pbar_test:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        test_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == y_batch).sum().item()\n        if pbar_test.n > 0:\n            pbar_test.set_postfix({'Loss': f'{test_loss / (pbar_test.n + 1):.4f}', 'Acc': f'{correct / len(test_dataset):.4f}'})\n        else:\n            pbar_test.set_postfix({'Loss': f'{test_loss:.4f}', 'Acc': f'N/A'})\ntest_accuracy = correct / len(test_dataset)\nprint(f'Test Loss: {test_loss / len(test_loader)}, Accuracy: {test_accuracy:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T16:05:58.082381Z","iopub.execute_input":"2025-03-16T16:05:58.082733Z","iopub.status.idle":"2025-03-16T16:06:02.199756Z","shell.execute_reply.started":"2025-03-16T16:05:58.082703Z","shell.execute_reply":"2025-03-16T16:06:02.199106Z"}},"outputs":[],"execution_count":null}]}