{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "INPUT_DIR = \"../dataset/raw data\"  # Folder containing genre subdirectories with 30-second audio files\n",
    "OUTPUT_DIR = \"../dataset/melspectrograms\"  # Folder where generated images will be saved\n",
    "METADATA_DIR = \"../dataset/metadata\"  # Directory for metadata files\n",
    "\n",
    "SPLIT_RATIOS = {\"train\": 0.8, \"validation\": 0.1, \"test\": 0.1}\n",
    "\n",
    "# Audio processing parameters\n",
    "SAMPLE_RATE = 22050       \n",
    "SEGMENT_DURATION = 3      \n",
    "NUM_SEGMENTS = 10        \n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata directory\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_dirs():\n",
    "    \"\"\"Create train, validation, and test directories for each genre.\"\"\"\n",
    "    for split in SPLIT_RATIOS.keys():\n",
    "        for genre in os.listdir(INPUT_DIR):\n",
    "            genre_dir = os.path.join(INPUT_DIR, genre)\n",
    "            if os.path.isdir(genre_dir):\n",
    "                output_genre_dir = os.path.join(OUTPUT_DIR, split, genre)\n",
    "                os.makedirs(output_genre_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_split():\n",
    "    \"\"\"Randomly assign a segment to train, validation, or test based on SPLIT_RATIOS.\"\"\"\n",
    "    rnd = random.random()\n",
    "    cumulative = 0.0\n",
    "    for split, ratio in SPLIT_RATIOS.items():\n",
    "        cumulative += ratio\n",
    "        if rnd < cumulative:\n",
    "            return split\n",
    "    return \"train\"  # fallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mel_spectrogram(mel_db, sr, output_filepath):\n",
    "    \"\"\"Save the Mel spectrogram as a JPEG image without axes.\"\"\"\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    # Display the spectrogram;\n",
    "    librosa.display.specshow(mel_db, sr=sr, hop_length=HOP_LENGTH, \n",
    "                             x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(output_filepath, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(filepath, genre, metadata_dict):\n",
    "    \"\"\"Load an audio file, split into segments, generate and save Mel spectrograms.\"\"\"\n",
    "    try:\n",
    "        # Load the full audio file\n",
    "        y, sr = librosa.load(filepath, sr=SAMPLE_RATE)\n",
    "        total_samples = len(y)\n",
    "        samples_per_segment = int(SAMPLE_RATE * SEGMENT_DURATION)\n",
    "        \n",
    "        # Ensure the audio file has the expected length\n",
    "        if total_samples < samples_per_segment * NUM_SEGMENTS:\n",
    "            warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
    "            metadata_dict[\"skipped_files\"].append(filepath)\n",
    "            return\n",
    "        \n",
    "        # Process each segment\n",
    "        for i in range(NUM_SEGMENTS):\n",
    "            start = i * samples_per_segment\n",
    "            end = start + samples_per_segment\n",
    "            segment = y[start:end]\n",
    "            \n",
    "            # Compute the Mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(y=segment, sr=sr, n_fft=N_FFT,\n",
    "                                                  hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
    "            # Convert to decibels for visualization\n",
    "            mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # Assign the segment to a split\n",
    "            split = assign_split()\n",
    "            # Track split assignments\n",
    "            metadata_dict[\"split_counts\"][split] += 1\n",
    "            \n",
    "            # Construct the output filepath. Using the original file's basename (without extension)\n",
    "            base_filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "            output_filename = f\"{base_filename}_segment{i+1}.jpg\"\n",
    "            output_path = os.path.join(OUTPUT_DIR, split, genre, output_filename)\n",
    "            \n",
    "            # Save the spectrogram as a jpg file\n",
    "            save_mel_spectrogram(mel_db, sr, output_path)\n",
    "            \n",
    "            # Add to metadata\n",
    "            metadata_dict[\"files\"].append({\n",
    "                \"original_file\": filepath,\n",
    "                \"segment\": i+1,\n",
    "                \"genre\": genre,\n",
    "                \"split\": split,\n",
    "                \"spectrogram_path\": output_path\n",
    "            })\n",
    "            \n",
    "            # Track genre counts\n",
    "            metadata_dict[\"genre_counts\"][genre] += 1\n",
    "            \n",
    "            # For the first segment of the first few files per genre, save a preview with labels\n",
    "            if i == 0 and metadata_dict[\"genre_preview_counts\"][genre] < 3:\n",
    "                save_preview_spectrogram(mel_db, sr, genre, base_filename)\n",
    "                metadata_dict[\"genre_preview_counts\"][genre] += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        metadata_dict[\"errors\"].append(f\"Error processing {filepath}: {str(e)}\")\n",
    "        warnings.warn(f\"Error processing {filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preview_spectrogram(mel_db, sr, genre, base_filename):\n",
    "    \"\"\"Save a labeled preview spectrogram for visualization purposes.\"\"\"\n",
    "    preview_dir = os.path.join(METADATA_DIR, \"previews\")\n",
    "    os.makedirs(preview_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    librosa.display.specshow(mel_db, sr=sr, hop_length=HOP_LENGTH, \n",
    "                           x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel Spectrogram - {genre}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(preview_dir, f\"{genre}_{base_filename}_preview.jpg\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_split_distribution(metadata):\n",
    "    \"\"\"Verify that the split distribution matches the expected ratios.\"\"\"\n",
    "    total = sum(metadata[\"split_counts\"].values())\n",
    "    actual_ratios = {split: count/total for split, count in metadata[\"split_counts\"].items()}\n",
    "    \n",
    "    print(\"\\nSplit Distribution Verification:\")\n",
    "    print(f\"Target ratios: {SPLIT_RATIOS}\")\n",
    "    print(f\"Actual ratios: {actual_ratios}\")\n",
    "    \n",
    "    # Calculate absolute differences\n",
    "    differences = {split: abs(SPLIT_RATIOS[split] - actual_ratios[split]) \n",
    "                  for split in SPLIT_RATIOS.keys()}\n",
    "    print(f\"Differences: {differences}\")\n",
    "    \n",
    "    # Check if any difference is more than 5% (a reasonable threshold)\n",
    "    if any(diff > 0.05 for diff in differences.values()):\n",
    "        print(\"WARNING: Split distribution differs from target by more than 5%\")\n",
    "    else:\n",
    "        print(\"Split distribution is close to target (within 5% tolerance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_statistics(metadata):\n",
    "    \"\"\"Generate statistics about the dataset.\"\"\"\n",
    "    total_files = len(metadata[\"files\"])\n",
    "    \n",
    "    # Create DataFrame for easier analysis\n",
    "    df = pd.DataFrame(metadata[\"files\"])\n",
    "    \n",
    "    print(\"\\n=== Dataset Statistics ===\")\n",
    "    print(f\"Total spectrograms generated: {total_files}\")\n",
    "    print(f\"Genres: {list(metadata['genre_counts'].keys())}\")\n",
    "    \n",
    "    # Per genre counts\n",
    "    print(\"\\nSpectrograms per genre:\")\n",
    "    for genre, count in metadata[\"genre_counts\"].items():\n",
    "        print(f\"  {genre}: {count}\")\n",
    "    \n",
    "    # Per split counts\n",
    "    print(\"\\nSpectrograms per split:\")\n",
    "    for split, count in metadata[\"split_counts\"].items():\n",
    "        print(f\"  {split}: {count}\")\n",
    "    \n",
    "    # Cross-tabulation of genres and splits\n",
    "    if total_files > 0:\n",
    "        print(\"\\nDistribution across genres and splits:\")\n",
    "        split_genre_table = pd.crosstab(df['genre'], df['split'])\n",
    "        print(split_genre_table)\n",
    "    \n",
    "    # Error summary\n",
    "    if metadata[\"errors\"]:\n",
    "        print(f\"\\nTotal errors: {len(metadata['errors'])}\")\n",
    "        print(\"First 5 errors:\")\n",
    "        for error in metadata[\"errors\"][:5]:\n",
    "            print(f\"  {error}\")\n",
    "    else:\n",
    "        print(\"\\nNo errors occurred during processing.\")\n",
    "    \n",
    "    if metadata[\"skipped_files\"]:\n",
    "        print(f\"\\nTotal skipped files: {len(metadata['skipped_files'])}\")\n",
    "    else:\n",
    "        print(\"\\nNo files were skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(metadata):\n",
    "    \"\"\"Save metadata to JSON and CSV files.\"\"\"\n",
    "    # Save full metadata as JSON\n",
    "    with open(os.path.join(METADATA_DIR, 'dataset_metadata.json'), 'w') as f:\n",
    "        # Convert Counter objects to dictionaries for JSON serialization\n",
    "        json_metadata = metadata.copy()\n",
    "        json_metadata[\"genre_counts\"] = dict(metadata[\"genre_counts\"])\n",
    "        json_metadata[\"split_counts\"] = dict(metadata[\"split_counts\"])\n",
    "        json_metadata[\"genre_preview_counts\"] = dict(metadata[\"genre_preview_counts\"])\n",
    "        json.dump(json_metadata, f, indent=2)\n",
    "    \n",
    "    # Save file listing as CSV for easy loading in ML pipelines\n",
    "    if metadata[\"files\"]:\n",
    "        df = pd.DataFrame(metadata[\"files\"])\n",
    "        df.to_csv(os.path.join(METADATA_DIR, 'dataset_files.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(metadata):\n",
    "    \"\"\"Create visualizations of the dataset distribution.\"\"\"\n",
    "    if not metadata[\"files\"]:\n",
    "        print(\"No files to visualize.\")\n",
    "        return\n",
    "    \n",
    "    # Create a DataFrame from the files metadata\n",
    "    df = pd.DataFrame(metadata[\"files\"])\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Genre distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    genre_counts = df['genre'].value_counts()\n",
    "    genre_counts.plot(kind='bar')\n",
    "    plt.title('Number of Spectrograms per Genre')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 2: Split distribution\n",
    "    plt.subplot(2, 2, 2)\n",
    "    split_counts = df['split'].value_counts()\n",
    "    split_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Distribution of Train/Validation/Test Splits')\n",
    "    \n",
    "    # Plot 3: Heatmap of genre vs split\n",
    "    plt.subplot(2, 2, 3)\n",
    "    cross_tab = pd.crosstab(df['genre'], df['split'])\n",
    "    plt.imshow(cross_tab, cmap='viridis')\n",
    "    plt.colorbar(label='Count')\n",
    "    plt.xticks(range(len(cross_tab.columns)), cross_tab.columns, rotation=45)\n",
    "    plt.yticks(range(len(cross_tab.index)), cross_tab.index)\n",
    "    plt.title('Genre vs Split Distribution')\n",
    "    \n",
    "    # Plot 4: Segment distribution (should be uniform)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    segment_counts = df['segment'].value_counts().sort_index()\n",
    "    segment_counts.plot(kind='bar')\n",
    "    plt.title('Number of Spectrograms per Segment Position')\n",
    "    plt.xlabel('Segment Position')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(METADATA_DIR, 'dataset_visualization.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Dataset visualization saved to {os.path.join(METADATA_DIR, 'dataset_visualization.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output_directory():\n",
    "    \"\"\"Clean the output directory if it exists.\"\"\"\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"Cleaning output directory: {OUTPUT_DIR}\")\n",
    "        try:\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "            print(\"Output directory cleaned successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning output directory: {e}\")\n",
    "            print(\"Continuing with existing directory.\")\n",
    "    \n",
    "    # Recreate the main output directory\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_processing(metadata_path=None):\n",
    "    \"\"\"Resume processing from a saved state if metadata exists.\"\"\"\n",
    "    processed_files = set()\n",
    "    \n",
    "    if metadata_path and os.path.exists(metadata_path):\n",
    "        try:\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                saved_metadata = json.load(f)\n",
    "            \n",
    "            # Extract already processed files\n",
    "            for item in saved_metadata[\"files\"]:\n",
    "                processed_files.add(item[\"original_file\"])\n",
    "            \n",
    "            print(f\"Resuming from previous run. {len(processed_files)} files already processed.\")\n",
    "            return processed_files\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading previous metadata: {e}\")\n",
    "            print(\"Starting from scratch.\")\n",
    "    \n",
    "    return processed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration options - Modify these variables as needed\n",
    "# Set these variables to control execution\n",
    "CLEAN_OUTPUT_DIR = False  # Set to True to clean the output directory before processing\n",
    "RESUME_PROCESSING = False  # Set to True to resume from a previous run\n",
    "SAVE_METADATA_INTERVAL = 10  # Save metadata every N files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metadata and directories\n",
    "# Initialize metadata tracking\n",
    "metadata = {\n",
    "    \"files\": [],\n",
    "    \"errors\": [],\n",
    "    \"skipped_files\": [],\n",
    "    \"genre_counts\": Counter(),\n",
    "    \"split_counts\": Counter(),\n",
    "    \"genre_preview_counts\": Counter()\n",
    "}\n",
    "\n",
    "# Clean output directory if requested\n",
    "if CLEAN_OUTPUT_DIR:\n",
    "    clean_output_directory()\n",
    "\n",
    "# Set up for resuming if requested\n",
    "processed_files = set()\n",
    "if RESUME_PROCESSING:\n",
    "    metadata_path = os.path.join(METADATA_DIR, 'dataset_metadata.json')\n",
    "    processed_files = resume_processing(metadata_path)\n",
    "\n",
    "# Create the output directory structure\n",
    "create_output_dirs()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: blues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blues: 100%|██████████| 100/100 [01:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: classical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classical:  49%|████▉     | 49/100 [00:32<00:40,  1.27it/s]C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\classical\\classical.00049.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "Processing classical:  51%|█████     | 51/100 [00:33<00:29,  1.64it/s]C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\classical\\classical.00051.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "Processing classical: 100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing country:   3%|▎         | 3/100 [00:03<01:38,  1.02s/it]C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\country\\country.00003.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\country\\country.00004.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "Processing country:   7%|▋         | 7/100 [00:04<01:00,  1.54it/s]C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\country\\country.00007.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "Processing country: 100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre: disco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing disco:  14%|█▍        | 14/100 [00:14<01:14,  1.15it/s]C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_16824\\2015281573.py:11: UserWarning: Warning: ../dataset/raw data\\disco\\disco.00014.wav is shorter than expected. Skipping.\n",
      "  warnings.warn(f\"Warning: {filepath} is shorter than expected. Skipping.\")\n",
      "Processing disco:  73%|███████▎  | 73/100 [02:02<01:41,  3.76s/it]"
     ]
    }
   ],
   "source": [
    "# Main processing loop\n",
    "# Process all genres and audio files\n",
    "for genre in os.listdir(INPUT_DIR):\n",
    "    print(f'Genre: {genre}')\n",
    "    genre_dir = os.path.join(INPUT_DIR, genre)\n",
    "    if not os.path.isdir(genre_dir):\n",
    "        continue  # skip non-directory files\n",
    "    \n",
    "    # Get list of audio files\n",
    "    audio_files = [\n",
    "        f for f in os.listdir(genre_dir) \n",
    "        if f.lower().endswith((\".wav\", \".mp3\", \".au\", \".ogg\", \".flac\"))\n",
    "    ]\n",
    "    \n",
    "    # Process each audio file in the genre directory\n",
    "    for filename in tqdm(audio_files, desc=f\"Processing {genre}\", leave=True):\n",
    "        filepath = os.path.join(genre_dir, filename)\n",
    "        \n",
    "        # Skip already processed files if resuming\n",
    "        if filepath in processed_files:\n",
    "            print(f\"Skipping already processed file: {filepath}\")\n",
    "            continue\n",
    "            \n",
    "        process_audio_file(filepath, genre, metadata)\n",
    "        \n",
    "        # Save metadata periodically\n",
    "        if len(metadata[\"files\"]) % SAVE_METADATA_INTERVAL == 0 and metadata[\"files\"]:\n",
    "            save_metadata(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final steps - analysis and reporting\n",
    "# Verify and analyze the final dataset\n",
    "verify_split_distribution(metadata)\n",
    "generate_dataset_statistics(metadata)\n",
    "save_metadata(metadata)\n",
    "visualize_dataset(metadata)\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Generated {len(metadata['files'])} spectrogram images.\")\n",
    "print(f\"Metadata saved to {METADATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
